{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raziehAskarizade/chatbot/blob/main/PA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe2cKY9kQJMT"
      },
      "source": [
        "# Labraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GosKZbpIRBuU",
        "outputId": "7873ae91-4fdc-4aa5-a35c-b773abc96dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# impoert libararies\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate, BatchNormalization, Conv2DTranspose, Concatenate, Cropping2D, ZeroPadding2D\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import keras\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# connect to one drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68y2vuCjgVdr"
      },
      "source": [
        "Unit ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "15mzr6JCeYt1"
      },
      "outputs": [],
      "source": [
        "# Define the U-Net architecture\n",
        "def unet(input_size=(256, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "\n",
        "    # Decoder\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "\n",
        "    up6 = Conv2D(512, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(drop5))\n",
        "    merge6 = conv4\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge7 = conv3\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv7))\n",
        "    merge8 = conv2\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2, 2))(conv8))\n",
        "    merge9 = conv1\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "\n",
        "    output = Conv2D(1, 1, activation='sigmoid')(conv9)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Qw20LOZtkH"
      },
      "source": [
        "UNET from Segmentation-of-Teeth-in-Panoramic-X-ray-Image-Using-U-Net\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TM0ox6XpZ0SI"
      },
      "outputs": [],
      "source": [
        "def UNET(input_shape=(512,512,1),last_activation='sigmoid'):\n",
        "    inputs=Input(shape=input_shape)\n",
        "\n",
        "    conv1 = Conv2D(32,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    d1=Dropout(0.1)(conv1)\n",
        "    conv2 = Conv2D(32,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d1)\n",
        "    b=BatchNormalization()(conv2)\n",
        "\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(b)\n",
        "    conv3 = Conv2D(64,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    d2=Dropout(0.2)(conv3)\n",
        "    conv4 = Conv2D(64,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d2)\n",
        "    b1=BatchNormalization()(conv4)\n",
        "\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(b1)\n",
        "    conv5 = Conv2D(128,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    d3=Dropout(0.3)(conv5)\n",
        "    conv6 = Conv2D(128,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d3)\n",
        "    b2=BatchNormalization()(conv6)\n",
        "\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(b2)\n",
        "    conv7 = Conv2D(256,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    d4=Dropout(0.4)(conv7)\n",
        "    conv8 = Conv2D(256,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d4)\n",
        "    b3=BatchNormalization()(conv8)\n",
        "\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(b3)\n",
        "    conv9 = Conv2D(512,(3,3),activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    d5=Dropout(0.5)(conv9)\n",
        "    conv10 = Conv2D(512,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d5)\n",
        "    b4=BatchNormalization()(conv10)\n",
        "\n",
        "\n",
        "    conv11 = Conv2DTranspose(512,(4,4), activation = 'relu', padding = 'same', strides=(2,2),kernel_initializer = 'he_normal')(b4)\n",
        "    x= concatenate([conv11,conv8])\n",
        "    conv12 = Conv2D(256,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x)\n",
        "    d6=Dropout(0.4)(conv12)\n",
        "    conv13 = Conv2D(256,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d6)\n",
        "    b5=BatchNormalization()(conv13)\n",
        "\n",
        "\n",
        "    conv14 = Conv2DTranspose(256,(4,4), activation = 'relu', padding = 'same', strides=(2,2),kernel_initializer = 'he_normal')(b5)\n",
        "    x1=concatenate([conv14,conv6])\n",
        "    conv15 = Conv2D(128,3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x1)\n",
        "    d7=Dropout(0.3)(conv15)\n",
        "    conv16 = Conv2D(128,3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d7)\n",
        "    b6=BatchNormalization()(conv16)\n",
        "\n",
        "    conv17 = Conv2DTranspose(128,(4,4), activation = 'relu', padding = 'same',strides=(2,2), kernel_initializer = 'he_normal')(b6)\n",
        "    x2=concatenate([conv17,conv4])\n",
        "    conv18 = Conv2D(64,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x2)\n",
        "    d8=Dropout(0.2)(conv18)\n",
        "    conv19 = Conv2D(64,(3,3) ,activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d8)\n",
        "    b7=BatchNormalization()(conv19)\n",
        "\n",
        "    conv20 = Conv2DTranspose(64,(4,4), activation = 'relu', padding = 'same',strides=(2,2), kernel_initializer = 'he_normal')(b7)\n",
        "    x3=concatenate([conv20,conv2])\n",
        "    conv21 = Conv2D(32,(3,3) ,activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(x3)\n",
        "    d9=Dropout(0.1)(conv21)\n",
        "    conv22 = Conv2D(32,(3,3), activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(d9)\n",
        "\n",
        "    outputs = Conv2D(1,(1,1), activation = last_activation, padding = 'same', kernel_initializer = 'he_normal')(conv22)\n",
        "    model2 = Model( inputs = inputs, outputs = outputs)\n",
        "\n",
        "    return model2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiaK52wE2vyO"
      },
      "source": [
        "https://github.com/lorisrossi/unet/blob/master/unet.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fwL0fPod2zJF"
      },
      "outputs": [],
      "source": [
        "def blob(shape=(512,512,1)):\n",
        "  # U-Net architecture\n",
        "\n",
        "  # Contracting path\n",
        "  model_in = Input(shape=shape)\n",
        "  conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(model_in)\n",
        "  conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
        "  down1 = MaxPooling2D((2, 2), strides=2)(conv1)\n",
        "\n",
        "  conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(down1)\n",
        "  conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
        "  down2 = MaxPooling2D((2, 2), strides=2)(conv2)\n",
        "\n",
        "  conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(down2)\n",
        "  conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
        "  down3 = MaxPooling2D((2, 2), strides=2)(conv3)\n",
        "\n",
        "  conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(down3)\n",
        "  conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
        "  down4 = MaxPooling2D((2, 2), strides=2)(conv4)\n",
        "\n",
        "  conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(down4)\n",
        "  conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "  # Expansive path\n",
        "  up1 = UpSampling2D((2, 2))(conv5)\n",
        "  conv6 = Conv2D(512, (2, 2), activation='relu', padding='same')(up1)\n",
        "  concat1 = concatenate([conv4, conv6], axis=3)\n",
        "  conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(concat1)\n",
        "  conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "  up2 = UpSampling2D((2, 2))(conv6)\n",
        "  conv7 = Conv2D(256, (2, 2), activation='relu', padding='same')(up2)\n",
        "  concat2 = concatenate([conv3, conv7], axis=3)\n",
        "  conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(concat2)\n",
        "  conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "  up3 = UpSampling2D((2, 2))(conv7)\n",
        "  conv8 = Conv2D(128, (2, 2), activation='relu', padding='same')(up3)\n",
        "  concat3 = concatenate([conv2, conv8], axis=3)\n",
        "  conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(concat3)\n",
        "  conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "  up4 = UpSampling2D((2, 2))(conv8)\n",
        "  conv9 = Conv2D(64, (2, 2), activation='relu', padding='same')(up4)\n",
        "  concat4 = concatenate([conv1, conv9], axis=3)\n",
        "  conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(concat4)\n",
        "  conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "  conv10 = Conv2D(1, (1, 1), activation='softmax', padding='same')(conv9)\n",
        "\n",
        "  model = Model(model_in, conv10)\n",
        "  print(conv10.shape)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOJAD93ZS1is"
      },
      "source": [
        "FCN dinamic    \n",
        "\n",
        "   different size for each traning set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QooCnwV7S1it"
      },
      "outputs": [],
      "source": [
        "def fcn(input_size=(None, None, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4)\n",
        "\n",
        "    # Decoder\n",
        "    up5 = UpSampling2D(size=(2, 2))(drop4)\n",
        "    up5 = Conv2D(256, 2, activation='relu', padding='same', kernel_initializer='he_normal')(up5)\n",
        "    merge5 = concatenate([conv3, up5], axis=3)\n",
        "    conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge5)\n",
        "    conv5 = Conv2D(256, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv5)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv5)\n",
        "    up6 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(up6)\n",
        "    merge6 = concatenate([conv2, up6], axis=3)\n",
        "    conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge6)\n",
        "    conv6 = Conv2D(128, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv6)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    up7 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(up7)\n",
        "    print(up7.shape)\n",
        "    merge7 = concatenate([conv1, up7], axis=3)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(merge7)\n",
        "    conv7 = Conv2D(64, 3, activation='relu', padding='same', kernel_initializer='he_normal')(conv7)\n",
        "\n",
        "    # Output\n",
        "    output = Conv2D(1, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "    # Model\n",
        "    model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkDsqKsUgh3o"
      },
      "source": [
        "Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8T_Reh_hemL-"
      },
      "outputs": [],
      "source": [
        "def train_model(X_train, Y_train, X_test, Y_test, param_grid, input_size, verbose=1, best_model=None):\n",
        "\n",
        "    # Create the model with the current set of hyperparameters\n",
        "    # model = UNET(input_size)\n",
        "    # model = fcn(input_size)\n",
        "    model = blob(input_size)\n",
        "    metrics = ['accuracy']\n",
        "    model.compile(optimizer=keras.optimizers.Adam(lr=param_grid['lr']), loss='binary_crossentropy', metrics= metrics)\n",
        "    # Save the mode architecture\n",
        "    compiled_model = model.save('/content/drive/MyDrive/compiled')\n",
        "\n",
        "    # Train the model with the current set of hyperparameters\n",
        "    fitness = model.fit(X_train, Y_train, batch_size=param_grid['batch_size'], epochs=param_grid['epochs'], verbose=verbose, validation_data=(X_test, Y_test))\n",
        "    trained_model = model.save('/content/drive/MyDrive/trained')\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    results = model.evaluate(X_test, Y_test)\n",
        "\n",
        "    # Create a DataFrame to store the results and save to a CSV file\n",
        "    df = pd.DataFrame({'Metric': model.metrics_names, 'Value': results})\n",
        "    df.to_csv('evaluation_results.csv', index=False)\n",
        "\n",
        "    return fitness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nre3_99Te8My"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(X_test, Y_test, threshold=0.5):\n",
        "  # if model stopped training or inttrupt or s.th\n",
        "  model = keras.models.load_model('/content/drive/MyDrive/trained')\n",
        "\n",
        "  # Predict the labels for the test set\n",
        "  Y_pred = model.predict(X_test)\n",
        "  Y_pred2 = Y_pred\n",
        "\n",
        "  Y_pred = (Y_pred > threshold).astype(int)\n",
        "  Y_test = np.where(Y_test > threshold, 1, 0)\n",
        "\n",
        "  # flatten the masks to 1D arrays\n",
        "  Y_test_flat = Y_test.ravel()\n",
        "  Y_pred_flat = Y_pred.ravel()\n",
        "\n",
        "  # Compute Pixel Accuracy\n",
        "  pa = np.sum(Y_test_flat == Y_pred_flat) / len(Y_test_flat)\n",
        "\n",
        "  # Compute confusion matrix\n",
        "  cm = confusion_matrix(Y_test_flat, Y_pred_flat)\n",
        "\n",
        "  # Compute IoU for each class\n",
        "  iou = np.diag(cm) / (np.sum(cm, axis=1) + np.sum(cm, axis=0) - np.diag(cm))\n",
        "  # Compute mean IoU\n",
        "  miou = np.mean(iou)\n",
        "\n",
        "  # calculate precision, recall, and f1-score for each segmentation class\n",
        "  # set average='weighted' to calculate weighted averages of the metrics\n",
        "  precision = precision_score(Y_test_flat, Y_pred_flat, average='weighted', zero_division=0)\n",
        "  recall = recall_score(Y_test_flat, Y_pred_flat, average='weighted', zero_division=0)\n",
        "  f1 = f1_score(Y_test_flat, Y_pred_flat, average='weighted', zero_division=0)\n",
        "\n",
        "  # Calculate the evaluation metrics\n",
        "  # wrong way!!\n",
        "  accuracy = accuracy_score(Y_test_flat, Y_pred_flat)\n",
        "\n",
        "  # Return the evaluation metrics as a dictionary\n",
        "  return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'Pixel_Accuracy' : pa, 'mIoU' : miou}, X_test, Y_pred2, Y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNwzVqnHgl6K"
      },
      "source": [
        "Image processing On raw dataset and labels ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E32K5CUGQGaB"
      },
      "outputs": [],
      "source": [
        "# image processing on raw images\n",
        "def imgp_raw(path, size, the1, the2, the3=127, the4=200):\n",
        "\n",
        "  image = cv.imread(path)\n",
        "\n",
        "  # Resize the image to the input size of the U-Net model\n",
        "  image = cv.resize(image,(size,size))\n",
        "\n",
        "\n",
        "  # convert to grayscale\n",
        "  img_ = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "  img_np = np.asarray(img_)\n",
        "\n",
        "\n",
        "  # remove small obj\n",
        "  kernel = np.ones((3, 3), np.float32)\n",
        "  img_nr = cv.morphologyEx(img_np, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "  # threshold\n",
        "  img_th = cv.threshold(img_nr, the1, the2, cv.THRESH_TRUNC)[1]\n",
        "\n",
        "  # normalize\n",
        "  dcm_gray = np.zeros([512, 512], dtype=np.uint8)\n",
        "  img_th = np.uint8(cv.normalize(img_th, dcm_gray, the3, the4, cv.NORM_INF))\n",
        "\n",
        "  # Enhancement\n",
        "  equalized = cv.equalizeHist(img_th)\n",
        "\n",
        "\n",
        "  # smoothing\n",
        "  gblur = cv.GaussianBlur(equalized, (3, 3), 0, 0, cv.BORDER_WRAP)\n",
        "  median = cv.medianBlur(gblur, 5)\n",
        "\n",
        "  # denoising\n",
        "  dst = cv.fastNlMeansDenoising(median, None, 20, 7, 21)\n",
        "\n",
        "  # Normalize the pixel values to [0, 1]\n",
        "  imagee = dst.astype(np.float32) / 255.0\n",
        "\n",
        "  # Add a channel dimension to the image\n",
        "  imagf = np.expand_dims(imagee, axis=-1)\n",
        "\n",
        "\n",
        "  return imagf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PdCnU0c6Ta9l"
      },
      "outputs": [],
      "source": [
        "# image processing on labeled images\n",
        "def imgp_label(path,size, the1, the2):\n",
        "  image = cv.imread(path)\n",
        "\n",
        "  # Resize the image to the input size of the U-Net model\n",
        "  # height, width = image.shape[:2]\n",
        "  # if max(height, width) <= size:\n",
        "  #   pass\n",
        "  # if height > width:\n",
        "  #   new_height = size\n",
        "  #   new_width = int(width * (size / height))\n",
        "  # else:\n",
        "  #   new_width = size\n",
        "  #   new_height = int(height * (size / width))\n",
        "  # image = cv.resize(image, (new_height, new_height))\n",
        "\n",
        "  image = cv.resize(image, (size, size))\n",
        "\n",
        "  # remove small obj\n",
        "  kernel = np.ones((3, 3), np.float32)\n",
        "  img_nr = cv.morphologyEx(image, cv.MORPH_OPEN, kernel)\n",
        "\n",
        "  # Convert the image to grayscale\n",
        "  image = cv.cvtColor(img_nr, cv.COLOR_BGR2GRAY)\n",
        "\n",
        "  # threshold\n",
        "  img_ = cv.threshold(image, the1, the2, cv.THRESH_BINARY)[1]\n",
        "\n",
        "  # smoothing\n",
        "  gblur = cv.GaussianBlur(img_, (3, 3), 0, 0, cv.BORDER_WRAP)\n",
        "  median = cv.medianBlur(gblur, 5)\n",
        "\n",
        "  # denoising\n",
        "  dst = cv.fastNlMeansDenoising(median, None, 20, 7, 21)\n",
        "\n",
        "  # Normalize the pixel values to [0, 1]\n",
        "  imagee = dst.astype(np.float32) / 255.0\n",
        "\n",
        "  # Add a channel dimension to the image\n",
        "  mask = np.expand_dims(imagee, axis=-1)\n",
        "\n",
        "  return mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulwE_bPShxmB"
      },
      "source": [
        ".npy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OUZ6RuR0Yy0q"
      },
      "outputs": [],
      "source": [
        "# convert images file to .npy\n",
        "def convert_npy(path_raw, path_label):\n",
        "\n",
        "  # Load the image filenames in the labeled directory\n",
        "  labeled_filenames = [filename for filename in os.listdir(path_label)]\n",
        "  raw_filenames = [filename for filename in os.listdir(path_raw)]\n",
        "\n",
        "  # Split data into train and test sets\n",
        "  X_train, X_test, Y_train, Y_test = train_test_split(raw_filenames, labeled_filenames, test_size=0.2, random_state=42)\n",
        "\n",
        "  # Load and preprocess the training and test images and labels\n",
        "  Y_train_labeled = np.array([imgp_label(os.path.join(path_label, filename), 460, 210, 255) for filename in Y_train])\n",
        "  X_train_raw = np.array([imgp_raw(os.path.join(path_raw, filename), 460, 160, 255) for filename in X_train])\n",
        "\n",
        "  Y_test_labeled = np.array([imgp_label(os.path.join(path_label, filename), 460, 210, 255) for filename in Y_test])\n",
        "  X_test_raw = np.array([imgp_raw(os.path.join(path_raw, filename), 460, 160, 255) for filename in X_test])\n",
        "\n",
        "\n",
        "  # Save the preprocessed datasets to numpy files\n",
        "  path = '/content/drive/MyDrive/'\n",
        "  np.save(path + 'Y_train.npy', Y_train_labeled)\n",
        "  np.save(path + 'X_train.npy', X_train_raw)\n",
        "  np.save(path + 'Y_test.npy', Y_test_labeled)\n",
        "  np.save(path + 'X_test.npy', X_test_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "12pppDJRob7D"
      },
      "outputs": [],
      "source": [
        "# !wget http://192.168.1.109:8000/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc2j_nQ4h1EC"
      },
      "source": [
        "All functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_zZFhu7Rb7yH",
        "outputId": "58c4ae32-2ea3-4452-ddd4-36e7938c6330"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-8552cde0e78e>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Evaluate the performance of the trained model on the binary thresholded test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mmetrics\u001b[0m \u001b[0;34m,\u001b[0m  \u001b[0mX_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_pred2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-822613d92166>\u001b[0m in \u001b[0;36mevaluate_model\u001b[0;34m(X_test, Y_test, threshold)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Predict the labels for the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mY_pred2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/up_sampling2d_3/resize/ResizeNearestNeighbor' defined at (most recent call last):\n    File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-13-8552cde0e78e>\", line 24, in <cell line: 24>\n      metrics ,  X_test2, Y_pred2, Y_test2 = evaluate_model(X_test, Y_test)\n    File \"<ipython-input-7-822613d92166>\", line 6, in evaluate_model\n      Y_pred = model.predict(X_test)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2382, in predict\n      tmp_batch_outputs = self.predict_function(iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2169, in predict_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2155, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2143, in run_step\n      outputs = model.predict_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 2111, in predict_step\n      return self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/layers/reshaping/up_sampling2d.py\", line 146, in call\n      return backend.resize_images(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 3702, in resize_images\n      x = tf.image.resize(x, new_shape, method=interpolations[interpolation])\nNode: 'model/up_sampling2d_3/resize/ResizeNearestNeighbor'\nOOM when allocating tensor with shape[32,512,512,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/up_sampling2d_3/resize/ResizeNearestNeighbor}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_predict_function_42761]"
          ]
        }
      ],
      "source": [
        "# train model\n",
        "# convert_npy('/content/drive/MyDrive/raw','/content/drive/MyDrive/results')\n",
        "\n",
        "# Load the dataset\n",
        "path = '/content/drive/MyDrive/dataset/'\n",
        "X_train = np.load(path + 'X_train.npy')\n",
        "Y_train = np.load(path + 'Y_train.npy')\n",
        "X_test = np.load(path + 'X_test.npy')\n",
        "Y_test = np.load(path + 'Y_test.npy')\n",
        "\n",
        "\n",
        "# Specify the hyperparameter\n",
        "# It can be get a lists of values and take a for loop to tain model for all possible hyperparameter\n",
        "param_grid = {\n",
        "    'lr': 1e-4,\n",
        "    'batch_size': 5,\n",
        "    'epochs': 30 }\n",
        "\n",
        "# Train the model with different hyperparameters and find the best combination\n",
        "# train_model(X_train, Y_train, X_test, Y_test, param_grid, (512, 512, 1))\n",
        "\n",
        "\n",
        "# Evaluate the performance of the trained model on the binary thresholded test set\n",
        "metrics ,  X_test2, Y_pred2, Y_test2 = evaluate_model(X_test, Y_test)\n",
        "\n",
        "print(metrics)\n",
        "\n",
        "x = np.arange(X_test2[0].ravel().size)\n",
        "# for i in range(200):\n",
        "\n",
        "#   fig, axs = plt.subplots(1, 3, figsize=(10, 3))\n",
        "\n",
        "#   axs[0].imshow(X_test2[i].squeeze())\n",
        "#   axs[0].set_title('X_test2')\n",
        "\n",
        "#   axs[1].imshow(Y_test2[i].squeeze())\n",
        "#   axs[1].set_title('Y_test2')\n",
        "\n",
        "#   axs[2].imshow(Y_pred2[i].squeeze())\n",
        "#   axs[2].set_title('Predicted')\n",
        "\n",
        "#   plt.savefig(os.path.join('/content/drive/MyDrive/plots', \"plot{}.png\".format(i)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iM8ZnSPQQN-b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}